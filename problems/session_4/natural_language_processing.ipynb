{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing - Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYYTxll6wm6i"
   },
   "source": [
    "**Author:** Ties de Kok ([Personal Website](https://www.tiesdekok.com))  <br>\n",
    "**Last updated:** September 2021  \n",
    "**Python version:** Python 3.6+     \n",
    "**Recommended environment: `researchPython`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "recommendedEnvironment = 'researchPython'\n",
    "if os.environ['CONDA_DEFAULT_ENV'] != recommendedEnvironment:\n",
    "    print('Warning: it does not appear you are using the {0} environment, did you run \"conda activate {0}\" before starting Jupyter?'.format(recommendedEnvironment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border-style: solid; padding: 10px; border-color: black; border-width:5px;  text-align: left; margin-top:20px; margin-bottom: 20px;'>\n",
    "<span style='color:black; font-size: 30px; font-weight:bold;'>Introduction</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDCbIPT4wm6l"
   },
   "source": [
    "<div style='border-style: solid; padding: 5px; border-color: darkred; border-width:5px;  text-align: center; margin-left: 100px; margin-right:100px;'>\n",
    "<span style='color:black; font-size: 20px; font-weight:bold;'> Make sure to open up the respective tutorial notebook(s)! <br> That is what you are expected to use as primary reference material. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant tutorial notebooks:\n",
    "\n",
    "1) [`0_python_basics.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/LearnPythonforResearch/blob/master/0_python_basics.ipynb)  \n",
    "\n",
    "\n",
    "2) [`2_handling_data.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/LearnPythonforResearch/blob/master/2_handling_data.ipynb)  \n",
    "\n",
    "\n",
    "3) [`NLP_Notebook.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/Python_NLP_Tutorial/blob/master/NLP_Notebook.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\n",
    "    'Tagger', 'DependencyParser', \n",
    "    'EntityRecognizer', 'TextCategorizer']\n",
    ") ## Note we disable most of this functionality here to speed up our code (as we don't need it for these tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have to replace the above with the code below if you installed the language model in an alternative way\n",
    "```python\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border-style: solid; padding: 10px; border-color: black; border-width:5px;  text-align: center; margin-top:20px; margin-bottom: 20px;'>\n",
    "<span style='color:black; font-size: 30px; font-weight:bold;'>Part 1 </span>\n",
    "</div>  \n",
    "\n",
    "<div style='border-style: solid; padding: 5px; border-color: darkred; border-width:5px;  text-align: center; margin-left: 100px; margin-right:100px;'>\n",
    "<span style='color:black; font-size: 15px; font-weight:bold;'> Note: feel free to add as many cells as you'd like to answer these problems, you don't have to fit it all in one cell. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Perform basic operations on a sample earnings transcript text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Load the following text file: `data > example_transcript.txt` into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Print the first 400 characters of the text file you just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Count the number of times the words `Alex` and `Angie` are mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Use the provided Regular Expression to capture all numbers prior to a \"%\"  \n",
    "Use this regular expression: `\\W([\\.\\d]{,})%`  \n",
    "**You can play around with this regular expression here: <a href='https://bit.ly/3heIqoG'>Test on Pythex.org</a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: try to explain to a neighbor / group member what the regular expression is doing\n",
    "You can use the cheatsheet on Pythex.org for reference.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d) Load the text into a Spacy object and split it into a list of  sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to evaluate how well it worked by inspecting various elements of the sentence list.\n",
    "\n",
    "Note: the beginning of the document contains meta data that are not normal sentences, so you might see some weird \"sentences\" at the beginning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the 140th sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Why is there a difference between what you see when you run `test_sentence` versus `print(test_sentence)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = 'Name: Hope Bancorp Inc\\nCompany Ticker: HOPE US Equity\\nDate: 2020-01-23\\nQ4 2019 Earnings Call\\nCompany Participants\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Hope Bancorp Inc\\nCompany Ticker: HOPE US Equity\\nDate: 2020-01-23\\nQ4 2019 Earnings Call\\nCompany Participants\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Hope Bancorp Inc\n",
      "Company Ticker: HOPE US Equity\n",
      "Date: 2020-01-23\n",
      "Q4 2019 Earnings Call\n",
      "Company Participants\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e) Parse out the following 3 blocks of text:\n",
    "\n",
    "* The meta data at the top   \n",
    "* The presentation portion  \n",
    "* The Q&A portion\n",
    "\n",
    "**Note:** you could do it based on the exact location (e.g, `text_file[:1234]`), however, that would only work for this file. Try to come up with a solution that would work for all files that follow the same structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f) How many characters, sentences, words (tokens) do the presentation portion and the Q&A portion have?  \n",
    "\n",
    "Hint: use `Spacy` for the sentence and word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1g) Create a list of all the questions during the Q&A and include the person that asked the question   \n",
    "\n",
    "You should end up with 20 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1h) Modify the Q&A list by adding in the answer + answering person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this is not an easy question and will probably take you a while. If you are time constraint I would recommend to leave it until the end. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the first entry should (rougly) look like:\n",
    "```python\n",
    "qa_list[0] = \n",
    "{\n",
    "  'q_person': 'Christopher McGratty ',\n",
    "  'question': 'Great, thanks, good afternoon. Kevin maybe you could start -- or Alex on the margin, obviously the environment has got a little bit tougher for the banks. But you have this -- the ability to bring down deposit costs, which you talked about in your prepared remarks. I appreciate in the guidance for the first quarter, but if the rate outlook remains steady, how do we think about ultimate stability in the flow and the margin, where and kind of when?',\n",
    "  'answers': [{\n",
    "    'name': 'Alex Ko ',\n",
    "    'answer': 'Sure, sure. As I indicated, we would expect to have continued compression next quarter given the rate cuts that we have experienced especially October rate cut, it will continue next quarter. But as we indicated, our proactive deposit initiative as well as very disciplined pricing on the deposit, even though we have a very competitive -- competition on the loan rate is very still severe. We would expect to stabilize in the second quarter of 2020 in terms of net interest margin and then second half of the year, we would expect to start to increase.'\n",
    "  }]\n",
    "}\n",
    "```\n",
    "\n",
    "Make sure that it can handle cases where there are multiple answers:\n",
    "```python\n",
    "{\n",
    "    \"q_person\": \"Unidentified Participant\",\n",
    "    \"question\": \"Okay, thank you very much, I appreciate it.\",\n",
    "    \"answers\": [\n",
    "        {\n",
    "            \"name\": \"Kevin S. Kim \", \n",
    "            \"answer\": \"Thank you.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Operator\",\n",
    "            \"answer\": \"And the next question comes from Tim Coffey with Janney.\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border-style: solid; padding: 10px; border-color: black; border-width:5px;  text-align: left; margin-top:20px; margin-bottom: 20px;'>\n",
    "<span style='color:black; font-size: 30px; font-weight:bold;'>Part 2:</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create sentiment score based on Loughran and McDonald (2011)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sentiment score for MD&As based on the Loughran and McDonald (2011) word lists.    \n",
    "\n",
    "#### References  \n",
    "\n",
    "*Loughran, T., & McDonald, B. (2011). When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks. The Journal of Finance, 66(1), 35-65.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data to use\n",
    "\n",
    "I have included a random selection of 20 pre-processed MDA filings in the `data > MDA_files` folder. The filename is the unique identifier.   \n",
    "\n",
    "You will also find a file called `MDA_META_DF.xlsx` in the \"data\" folder, this contains the following meta-data for eaching MD&A: \n",
    "* filing date  \n",
    "* cik   \n",
    "* company name  \n",
    "* link to filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Load data into a dictionary with as key the filename and as value the content of the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files should all be in the following folder:  \n",
    "```\n",
    "Path.cwd() / 'data' / 'MDA_files'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Load the Loughran and McDonald master dictionary    \n",
    "**Note:** The Loughran and McDonald dictionary is included in the \"data\" folder: `LoughranMcDonald_MasterDictionary_2014.xlsx `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Create two lists: one containing all the negative words and the other one containing all the positive words   \n",
    "\n",
    "Note, you can treat any number that is not 0 as a 1:\n",
    "\n",
    "```python\n",
    "0       82776\n",
    "2009     2315    ## <-- 1\n",
    "2014       26    ## <-- 1\n",
    "2011       13    ## <-- 1\n",
    "2012        1    ## <-- 1\n",
    "```\n",
    "\n",
    "They include the year instead of a one for versioning purposes. \n",
    "\n",
    "**Tip:** I recommend to change all words to lowercase in this step so that you don't need to worry about that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) For each MD&A calculate the *total* number of times negative and positive words are mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** save the counts to a list where each entry is a list that contains the following three items: [*filename*, *total pos count*, *total neg count*], like this:\n",
    "> [   \n",
    " ['21344_0000021344-16-000050.txt', 474, 642],   \n",
    " ['21510_0000021510-16-000074.txt', 168, 208],  \n",
    " ['21665_0001628280-16-011343.txt', 240, 354],  \n",
    "> ....    \n",
    " ['47217_0000047217-16-000093.txt', 138, 360],    \n",
    " ['47518_0001214659-16-014806.txt', 202, 278],   \n",
    " ['49071_0000049071-16-000117.txt', 440, 570]   \n",
    " ]   \n",
    "\n",
    "You can verify that it worked by checking whether the the 3rd element (i.e. `list[2]`) equals:  \n",
    "> ['21665_0001628280-16-011343.txt', 240, 354]\n",
    "\n",
    "\n",
    "**Note 1:** make sure you also convert the text to lowercase.   \n",
    "**Note 2:** if your computer is pretty slow running this code you are fine to run it on the first 5 only.  \n",
    "**Note 3:** you might end up with a different number due to substring matches, we only want to count full matches:\n",
    "\n",
    "```python\n",
    "### For example, consider the positive word 'win'\n",
    "\n",
    "test_sen = \"They hockey team made a big win during the winter.\"\n",
    "\n",
    "test_sen.count('win')\n",
    "## gives --> 2 \n",
    "\n",
    "## We only want to count \"win\" not \"winter\", how do we solve that?\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e) Convert the list created in 3c into a Pandas DataFrame  \n",
    "**Hint:** Use the `columns=[...]` parameter to name the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f) Create a new column with a \"sentiment score\" for each MD&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following (imaginary) sentiment score:   \n",
    "\n",
    "$$\\frac{(Num\\ Positive\\ Words - Num\\ Negative\\ Words)}{Sum\\ of Pos\\ and\\ Neg\\ Words}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2g) Use the `MDA_META_DF` file to add the company name, filing date, and CIK to the sentiment dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
